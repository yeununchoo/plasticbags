{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9500a59d-c5b4-445f-95c3-569ead697c45",
   "metadata": {},
   "source": [
    "## Model 5: Boost Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a906e8-4e30-4472-9090-011bbf9cd0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_curve, auc, RocCurveDisplay\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "save_figures = False\n",
    "figure_path = \"../figures/models/\"\n",
    "# df_init = pd.read_parquet(\"../data/init.parquet\")\n",
    "# df_before = pd.read_parquet(\"../data/before_split.parquet\")\n",
    "# df_train = pd.read_parquet(\"../data/prep_train.parquet\")\n",
    "# df_val = pd.read_parquet(\"../data/prep_val.parquet\")\n",
    "# df_test = pd.read_parquet(\"../data/prep_test.parquet\")\n",
    "# df_tt_train = pd.read_parquet(\"../data/prep_tt_train.parquet\")\n",
    "# df_tt_test = pd.read_parquet(\"../data/prep_tt_test.parquet\")\n",
    "df_all = pd.read_parquet(\"../data/prep_all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcad624e-08ea-4b2a-81a5-98bfab72ab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Y2015</th>\n",
       "      <th>Year_Y2016</th>\n",
       "      <th>Country_England</th>\n",
       "      <th>Country_Wales</th>\n",
       "      <th>Supermarket_Asda</th>\n",
       "      <th>Supermarket_Tesco Extra</th>\n",
       "      <th>Supermarket_Tesco Metro</th>\n",
       "      <th>Supermarket_Waitrose</th>\n",
       "      <th>Time_Evening</th>\n",
       "      <th>Time_Morning</th>\n",
       "      <th>...</th>\n",
       "      <th>YearCountryAge_Y2016EnglandAge_g2</th>\n",
       "      <th>YearCountryAge_Y2016EnglandAge_g3</th>\n",
       "      <th>YearCountryAge_Y2016WalesAge_g1</th>\n",
       "      <th>YearCountryAge_Y2016WalesAge_g2</th>\n",
       "      <th>YearCountryAge_Y2016WalesAge_g3</th>\n",
       "      <th>YearCountryAge_nan</th>\n",
       "      <th>ObsSize</th>\n",
       "      <th>FemaleN</th>\n",
       "      <th>MaleN</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.471136</td>\n",
       "      <td>-1.156159</td>\n",
       "      <td>0.871226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.471136</td>\n",
       "      <td>-1.156159</td>\n",
       "      <td>0.871226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.471136</td>\n",
       "      <td>0.583858</td>\n",
       "      <td>-0.993069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.811174</td>\n",
       "      <td>2.323876</td>\n",
       "      <td>-0.993069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.471136</td>\n",
       "      <td>0.583858</td>\n",
       "      <td>-0.993069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_Y2015  Year_Y2016  Country_England  Country_Wales  Supermarket_Asda  \\\n",
       "0         0.0         1.0              0.0            1.0               0.0   \n",
       "1         0.0         1.0              0.0            1.0               0.0   \n",
       "2         0.0         1.0              0.0            1.0               0.0   \n",
       "3         0.0         1.0              0.0            1.0               0.0   \n",
       "4         0.0         1.0              0.0            1.0               0.0   \n",
       "\n",
       "   Supermarket_Tesco Extra  Supermarket_Tesco Metro  Supermarket_Waitrose  \\\n",
       "0                      0.0                      1.0                   0.0   \n",
       "1                      0.0                      1.0                   0.0   \n",
       "2                      0.0                      1.0                   0.0   \n",
       "3                      0.0                      1.0                   0.0   \n",
       "4                      0.0                      1.0                   0.0   \n",
       "\n",
       "   Time_Evening  Time_Morning  ...  YearCountryAge_Y2016EnglandAge_g2  \\\n",
       "0           0.0           1.0  ...                                0.0   \n",
       "1           0.0           1.0  ...                                0.0   \n",
       "2           0.0           1.0  ...                                0.0   \n",
       "3           0.0           1.0  ...                                0.0   \n",
       "4           0.0           1.0  ...                                0.0   \n",
       "\n",
       "   YearCountryAge_Y2016EnglandAge_g3  YearCountryAge_Y2016WalesAge_g1  \\\n",
       "0                                0.0                              0.0   \n",
       "1                                0.0                              0.0   \n",
       "2                                0.0                              1.0   \n",
       "3                                0.0                              0.0   \n",
       "4                                0.0                              0.0   \n",
       "\n",
       "   YearCountryAge_Y2016WalesAge_g2  YearCountryAge_Y2016WalesAge_g3  \\\n",
       "0                              1.0                              0.0   \n",
       "1                              1.0                              0.0   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              0.0   \n",
       "4                              0.0                              1.0   \n",
       "\n",
       "   YearCountryAge_nan   ObsSize   FemaleN     MaleN  y  \n",
       "0                 0.0 -0.471136 -1.156159  0.871226  1  \n",
       "1                 0.0 -0.471136 -1.156159  0.871226  1  \n",
       "2                 0.0 -0.471136  0.583858 -0.993069  1  \n",
       "3                 1.0  1.811174  2.323876 -0.993069  1  \n",
       "4                 0.0 -0.471136  0.583858 -0.993069  1  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6d25b5-4243-4c0c-91ba-dc1d1fb404a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df_all.iloc[:,0:-1].to_numpy()\n",
    "y_all = df_all[\"y\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e507f-1770-4fe8-99bc-5ee940652879",
   "metadata": {},
   "source": [
    "### Adaboost, Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d215c00-e1a8-4f1b-bf4d-837b50b04831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), random_state=132)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 132\n",
    "Dtree = DecisionTreeClassifier()\n",
    "Ada_grid = AdaBoostClassifier(base_estimator = Dtree, \n",
    "                              random_state = random_state)\n",
    "Ada_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4593bbba-e7f2-476b-941e-b1a3347e1672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),\n",
       "                                          random_state=132),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'base_estimator__max_depth': [1, 2, 3, 4],\n",
       "                         'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1,\n",
       "                                           1.1],\n",
       "                         'n_estimators': [8, 12, 16, 20, 24, 28, 32, 36, 40]},\n",
       "             scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_Ada = {'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1],\n",
    "              'n_estimators': [8, 12, 16, 20, 24, 28, 32, 36, 40],\n",
    "              'base_estimator__max_depth': [1, 2, 3, 4]}\n",
    "\n",
    "random_states_split = [123, 456, 789, \n",
    "                       741, 852, 963, \n",
    "                       159, 753, 951, 357]\n",
    "\n",
    "gridCV_Ada = GridSearchCV(estimator = Ada_grid, \n",
    "                          param_grid = params_Ada, \n",
    "                          scoring = 'balanced_accuracy', \n",
    "                          n_jobs = -2,\n",
    "                          refit = True, \n",
    "                          cv = 5, verbose = 1)\n",
    "gridCV_Ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7e3e96-9e1a-4747-9bdf-68ccf03152c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.6881407535138544\n",
      "{'base_estimator__max_depth': 1, 'learning_rate': 1, 'n_estimators': 16}\n",
      "Iteration 123: 40.285 seconds\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.6906000464831343\n",
      "{'base_estimator__max_depth': 1, 'learning_rate': 0.3, 'n_estimators': 36}\n",
      "Iteration 456: 40.097 seconds\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.6893166795552951\n",
      "{'base_estimator__max_depth': 2, 'learning_rate': 0.6, 'n_estimators': 24}\n",
      "Iteration 789: 40.792 seconds\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.6879047287105728\n",
      "{'base_estimator__max_depth': 1, 'learning_rate': 0.4, 'n_estimators': 36}\n",
      "Iteration 741: 42.010 seconds\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.693455539258397\n",
      "{'base_estimator__max_depth': 1, 'learning_rate': 0.8, 'n_estimators': 12}\n",
      "Iteration 852: 40.950 seconds\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.6991806855645863\n",
      "{'base_estimator__max_depth': 1, 'learning_rate': 0.7, 'n_estimators': 16}\n",
      "Iteration 963: 40.947 seconds\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.6937453422059028\n",
      "{'base_estimator__max_depth': 1, 'learning_rate': 0.9, 'n_estimators': 24}\n",
      "Iteration 159: 41.166 seconds\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.6978172600422577\n",
      "{'base_estimator__max_depth': 1, 'learning_rate': 0.5, 'n_estimators': 28}\n",
      "Iteration 753: 41.811 seconds\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.694485265891113\n",
      "{'base_estimator__max_depth': 3, 'learning_rate': 0.6, 'n_estimators': 12}\n",
      "Iteration 951: 40.988 seconds\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "0.6931905387358758\n",
      "{'base_estimator__max_depth': 1, 'learning_rate': 0.8, 'n_estimators': 28}\n",
      "Iteration 357: 41.206 seconds\n",
      "Wall time: 6min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "BalAccuracy_ada = []\n",
    "\n",
    "for each_rs in random_states_split:\n",
    "    start_time = time.time()\n",
    "    X_other_temp, X_test_temp, y_other_temp, y_test_temp = \\\n",
    "        train_test_split(X_all, y_all, \n",
    "                         test_size = 0.1, \n",
    "                         random_state = each_rs, \n",
    "                         stratify = y_all)\n",
    "    \n",
    "    n_each_class = [np.sum(y_other_temp == each_c) \n",
    "                    for each_c \n",
    "                    in np.unique(y_other_temp)]\n",
    "    weight_each_class = [1/each_n \n",
    "                         for each_n \n",
    "                         in n_each_class]\n",
    "    balanced_weights = np.array([weight_each_class[each_y] \n",
    "                                 for each_y \n",
    "                                 in y_other_temp])\n",
    "    \n",
    "    \n",
    "    gridCV_Ada.fit(X_other_temp, y_other_temp, \n",
    "                   groups = None, \n",
    "                   sample_weight = balanced_weights)\n",
    "    \n",
    "    BalAccuracy_ada.append(gridCV_Ada.best_score_)\n",
    "    \n",
    "    print(gridCV_Ada.best_score_, flush = True)\n",
    "    print(gridCV_Ada.best_params_, flush = True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Iteration {each_rs}: {end_time - start_time:.3f} seconds\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "551c5b9a-29fe-4f25-ab0c-e12f6eb9fd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6928 (0.0036)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{np.mean(BalAccuracy_ada):.4f} ({np.std(BalAccuracy_ada):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1abc275-bb7a-4ba3-9856-37c586ef6f89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gradient Boost, Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3756ce2-367f-4b65-ac67-7f2ba190c96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=50, random_state=132)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 132\n",
    "Gradient_grid = GradientBoostingClassifier(loss = 'deviance', \n",
    "                                           random_state= random_state, \n",
    "                                           n_estimators = 50, \n",
    "                                           min_samples_split = 2)\n",
    "Gradient_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcc57925-d1d0-4881-b297-d145c07019d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(n_estimators=50,\n",
       "                                                  random_state=132),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
       "                         'max_depth': [2, 3, 4, 5, 6],\n",
       "                         'max_features': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,\n",
       "                                          0.8, 0.9, 1.0]},\n",
       "             scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_Gradient = {'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "                   'max_features': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], \n",
    "                   'max_depth': [2, 3, 4, 5, 6]}\n",
    "\n",
    "random_states_split = [123, 456, 789, \n",
    "                       741, 852, 963, \n",
    "                       159, 753, 951, 357]\n",
    "\n",
    "gridCV_Gradient = GridSearchCV(estimator = Gradient_grid, \n",
    "                               param_grid = params_Gradient, \n",
    "                               scoring = 'balanced_accuracy', \n",
    "                               n_jobs = -2,\n",
    "                               refit = True, \n",
    "                               cv = 5, verbose = 1)\n",
    "gridCV_Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa682b76-0f4f-4b1f-981d-ed6ff6cb0256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.6924520052847376\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 0.3}\n",
      "Iteration 123: 47.110 seconds\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.6913559355461067\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'max_features': 0.4}\n",
      "Iteration 456: 48.559 seconds\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.6934289181241501\n",
      "{'learning_rate': 0.2, 'max_depth': 4, 'max_features': 0.1}\n",
      "Iteration 789: 48.528 seconds\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.6856184576743652\n",
      "{'learning_rate': 0.2, 'max_depth': 3, 'max_features': 0.1}\n",
      "Iteration 741: 48.419 seconds\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.6928683205470905\n",
      "{'learning_rate': 0.15, 'max_depth': 2, 'max_features': 0.2}\n",
      "Iteration 852: 48.238 seconds\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.7001775498857763\n",
      "{'learning_rate': 0.15, 'max_depth': 3, 'max_features': 0.2}\n",
      "Iteration 963: 49.985 seconds\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.6925060477041647\n",
      "{'learning_rate': 0.05, 'max_depth': 4, 'max_features': 0.3}\n",
      "Iteration 159: 48.422 seconds\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.6947247382179437\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 0.7}\n",
      "Iteration 753: 48.583 seconds\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.691769849341384\n",
      "{'learning_rate': 0.05, 'max_depth': 6, 'max_features': 0.1}\n",
      "Iteration 951: 48.310 seconds\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "0.6943408762885628\n",
      "{'learning_rate': 0.15, 'max_depth': 2, 'max_features': 0.1}\n",
      "Iteration 357: 48.293 seconds\n",
      "Wall time: 8min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "BalAccuracy_grad = []\n",
    "\n",
    "for each_rs in random_states_split:\n",
    "    start_time = time.time()\n",
    "    X_other_temp, X_test_temp, y_other_temp, y_test_temp = \\\n",
    "        train_test_split(X_all, y_all, \n",
    "                         test_size = 0.1, \n",
    "                         random_state = each_rs, \n",
    "                         stratify = y_all)\n",
    "    \n",
    "    n_each_class = [np.sum(y_other_temp == each_c) \n",
    "                    for each_c \n",
    "                    in np.unique(y_other_temp)]\n",
    "    weight_each_class = [1/each_n \n",
    "                         for each_n \n",
    "                         in n_each_class]\n",
    "    balanced_weights = np.array([weight_each_class[each_y] \n",
    "                                 for each_y \n",
    "                                 in y_other_temp])\n",
    "    \n",
    "    \n",
    "    gridCV_Gradient.fit(X_other_temp, y_other_temp, \n",
    "                   groups = None, \n",
    "                   sample_weight = balanced_weights)\n",
    "    \n",
    "    BalAccuracy_grad.append(gridCV_Gradient.best_score_)\n",
    "    \n",
    "    print(gridCV_Gradient.best_score_, flush = True)\n",
    "    print(gridCV_Gradient.best_params_, flush = True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Iteration {each_rs}: {end_time - start_time:.3f} seconds\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd9abdd6-b8c6-4859-9d6e-d1d58945ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6929 (0.0034)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{np.mean(BalAccuracy_grad):.4f} ({np.std(BalAccuracy_grad):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb870e5a-a398-47e4-8603-9bc8d6c6c40a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGB, Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cf21c05-f4c3-4461-b805-e68ac0aa0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states_split = [123, 456, 789, \n",
    "                       741, 852, 963, \n",
    "                       159, 753, 951, 357]\n",
    "\n",
    "params_XGB = {'learning_rate': [0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55],\n",
    "              'max_depth': [2, 3, 4, 5, 6],\n",
    "              'gamma': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1,  1.2],\n",
    "              'n_estimators': [10, 12, 16, 20, 24, 30, 35, 40]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33625d5b-73e7-4147-a74a-c4fe840369e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 1.0, 'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 12}\n",
      "Iteration 123: 266.052 seconds\n",
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 0.6, 'learning_rate': 0.45, 'max_depth': 2, 'n_estimators': 16}\n",
      "Iteration 456: 259.737 seconds\n",
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 0.5, 'learning_rate': 0.55, 'max_depth': 3, 'n_estimators': 20}\n",
      "Iteration 789: 262.148 seconds\n",
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 0.7, 'learning_rate': 0.55, 'max_depth': 5, 'n_estimators': 16}\n",
      "Iteration 741: 261.579 seconds\n",
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 0.5, 'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 20}\n",
      "Iteration 852: 265.376 seconds\n",
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 0.7, 'learning_rate': 0.35, 'max_depth': 3, 'n_estimators': 12}\n",
      "Iteration 963: 261.301 seconds\n",
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 0.9, 'learning_rate': 0.4, 'max_depth': 2, 'n_estimators': 20}\n",
      "Iteration 159: 266.787 seconds\n",
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 0.6, 'learning_rate': 0.55, 'max_depth': 2, 'n_estimators': 16}\n",
      "Iteration 753: 268.542 seconds\n",
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 1.1, 'learning_rate': 0.4, 'max_depth': 6, 'n_estimators': 10}\n",
      "Iteration 951: 264.460 seconds\n",
      "Fitting 5 folds for each of 2240 candidates, totalling 11200 fits\n",
      "{'gamma': 0.7, 'learning_rate': 0.35, 'max_depth': 2, 'n_estimators': 35}\n",
      "Iteration 357: 262.424 seconds\n",
      "Wall time: 43min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "BalAccuracy_xgb = []\n",
    "\n",
    "for each_rs in random_states_split:\n",
    "    start_time = time.time()\n",
    "    X_other_temp, X_test_temp, y_other_temp, y_test_temp = \\\n",
    "        train_test_split(X_all, y_all, \n",
    "                         test_size = 0.1, \n",
    "                         random_state = each_rs, \n",
    "                         stratify = y_all)\n",
    "    \n",
    "    n_each_class = [np.sum(y_other_temp == each_c) \n",
    "                    for each_c \n",
    "                    in np.unique(y_other_temp)]\n",
    "\n",
    "    xgb_pos_scale = n_each_class[0]/n_each_class[1]\n",
    "    \n",
    "    \n",
    "    xbg_random_state = 132\n",
    "    XGB_grid = XGBClassifier(random_state= xbg_random_state, \n",
    "                             use_label_encoder=False,  \n",
    "                             scale_pos_weight = xgb_pos_scale, \n",
    "                             eval_metric = 'auc')\n",
    "    \n",
    "    gridCV_XGB = GridSearchCV(estimator = XGB_grid, \n",
    "                           param_grid = params_XGB, \n",
    "                           scoring = 'balanced_accuracy', \n",
    "                           n_jobs = -2,\n",
    "                           refit = True, \n",
    "                           cv = 5, verbose = 1)\n",
    "    \n",
    "    gridCV_XGB.fit(X_other_temp, y_other_temp)\n",
    "    \n",
    "    BalAccuracy_xgb.append(gridCV_XGB.best_score_)\n",
    "    \n",
    "    print(gridCV_XGB.best_params_, flush = True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Iteration {each_rs}: {end_time - start_time:.3f} seconds\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "212b3ec1-5c99-4285-b48c-fb02dd78106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6944 (0.0037)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{np.mean(BalAccuracy_xgb):.4f} ({np.std(BalAccuracy_xgb):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "176482fe-4800-4a83-9260-c9f43074fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "boost_scores = {\"Ada\": BalAccuracy_ada, \n",
    "                \"Gradient\": BalAccuracy_grad, \n",
    "                \"XGB\": BalAccuracy_xgb}\n",
    "\n",
    "with open(\"../results/boost_scores.json\", \"w\") as outfile:\n",
    "    json.dump(boost_scores, outfile)\n",
    "    \n",
    "# with open(\"logistic.json\", \"r\") as readfile:\n",
    "#     dict_data = json.load(readfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a6f64-c68f-4898-b1d0-0223e32f22fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339adce6-ca13-4f91-b1f2-727dbdd78c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41069f1-9fe2-4693-928a-ff31193d174f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f748907-6d43-4215-82e0-1fefc8a2ee2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
